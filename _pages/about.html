ngs---
permalink: /
title: "AI-SENDS Lab - Clemson University"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
  - /home
  - /home.html
---
 
<html>
<head>
<style>
.myDiv {
  border-radius: 25px;
  border: 5px solid lightgray;
  background-color: white;
  text-align: center;
}

.news-list {
  list-style: none;
  padding-left: 0;
  margin-top: 0.5em;
}

.news-list li {
  margin-bottom: 0.25em;
  line-height: 1.35;
}

.news-date {
  color: #1f4fd8;
  font-weight: 600;
}
</style>
</head>

<body>

<p>
In the <strong>AI-SENDS</strong> (AI-based Sensing, Networking, and Data Services) Lab, we develop intelligent systems that
<strong>perceive, communicate, reason, and act cooperatively</strong> in uncertain, distributed, and resource-constrained environments.
Our research focuses on AI-native agents—from autonomous vehicles and drones to edge devices and assistive systems—that learn
the environment, anticipate the consequences of actions, and make decisions under networking, sensing, and computational constraints.
A unifying theme across our work is <strong>diversity-aware and communication-aware learning</strong>, bridging information theory,
machine learning, and <strong>large/vision language models (LLMs/VLMs)</strong> to enable coordinated autonomy at scale. 
My vision is applied research, and I welcome collaboration with researchers from diverse fields. 
Some of my active projects, including 

<ul>
  <li><strong>Diversity-aware Semantic Learning and Communication </strong> for Terrestrial and Aerial Monitoring Systems,</li>
  <li><strong>Multiple Instance Learning (MIL)</strong> and Diversity-aware Modeling for Biomedical Imaging,</li>
  <li><strong>VLM-Augmented Visual Interpretation </strong> for Visually Impaired Assistive Tools,</li>
  <li><strong>AI-enabled Drones with Overhead Manipulators </strong> for Safety-Critical Applications,</li>
  <li><strong>Nano-scaled 3D Image Reconstruction</strong> from Holographic Readings,</li>
  <li><strong>Multiple Instance Learning (MIL)</strong> and Diversity-aware Modeling for Biomedical Imaging,</li>
</ul> 

are supported by <strong>NSF</strong>, <strong>US Air Force Research Laboratory</strong>, <strong>USDA</strong>,
<strong>BMW Research Group</strong>, <strong>MIT Lincoln Laboratory</strong>,
<strong>Clemson VIPR (DoD)</strong>, <strong>SC EPSCoR</strong>, and <strong>Arizona Commerce Authority</strong>. 
See my <a href="../research">Research Page</a>for further details.
</p>

<!-- <p>
<strong>Curriculum Vitae:</strong>
<a href="/aisends.github.io/files/RaziCV.pdf" target="_blank">Download PDF</a>
</p> -->

<p>
<strong>Open Positions:</strong>  We occasionally have openings for MS, PhD, undergraduate, and part-time researchers.
Please email your CV and research background with the subject “Application for Open Positions”.
</p>

<h2>News</h2>
<ul class="news-list">

<li><span class="news-date">[2025/12]</span> Our paper “Factorized Transport Alignment for Multimodal and Multiview E-commerce Representation Learning” is accepted by <strong>WCDM 2026</strong>.</li>

<li><span class="news-date">[2025/11]</span>  My PhD student <strong>Xiwen Chen</strong> successfully defended his PhD thesis. Congratulations! Xiwen was a productive student and now, he is with <strong>Stanley Morgan</strong>. </li>

<li><span class="news-date">[2025/11]</span>  Our paper “RobustFormer: Noise-Robust Pre-training for Images and Videos” (<a href="https://arxiv.org/pdf/2411.13040" target="_blank">link</a>) is accepted by <strong>WACV 2026</strong>. </li>

<li><span class="news-date">[2025/11]</span>  Our paper “Prompt-OT: An Optimal Transport Regularization Paradigm for Knowledge Preservation in Vision-Language Model Adaptation” (<a href="https://arxiv.org/pdf/2503.08906" target="_blank">link</a>) is accepted in <strong>WACV 2026</strong>. </li>

<li> <span class="news-date">[2025/10]</span> Our paper “Extended Visibility of Autonomous Vehicles via Optimized Cooperative Perception under Imperfect Communication” (<a href="https://arxiv.org/pdf/2503.18192" target="_blank">link</a>) is accepted for publication in <strong>Transportation Research Part C: Emerging Technologies</strong>. </li>

<li><span class="news-date">[2025/9]</span> <strong>Funded project:</strong> “VIA-LLM: Visually-Impaired Assistive Tool with LLM-Based Reasoning” is awarded by <strong>SC EPSCoR GAIN</strong>.</li>

<li><span class="news-date">[2025/8]</span> Our paper “Toward AI-Driven Fire Imagery: Attributes, Challenges, Comparisons, and the Promise of VLMs and LLMs” (<a href="https://www.sciencedirect.com/science/article/pii/S266682702500146X" target="_blank">link</a>) is published in <strong>Machine Learning with Applications</strong>.</li>

<li><span class="news-date">[2025/7]</span> Our paper “Turbo-IRL: Enhancing Multi-Agent Systems Using Turbo Decoding-Inspired Deep Maximum Entropy Inverse Reinforcement Learning” (<a href="https://www.sciencedirect.com/science/article/pii/S0957417425023723" target="_blank">link</a>) is accepted for publication in <strong>Expert Systems with Applications</strong>.</li>

<li><span class="news-date">[2025/6]</span> Our paper “Fire and Smoke Datasets in 20 Years: An In-Depth Review” (<a href="https://arxiv.org/html/2503.14552v1" target="_blank">link</a>) is accepted for publication in <strong>Machine Learning with Applications</strong>.</li>

<li><span class="news-date">[2025/5]</span> Our paper “How Effective Can Dropout Be in Multiple Instance Learning?” (<a href="https://arxiv.org/pdf/2504.14783" target="_blank">link</a>) is accepted by <strong>ICML 2025</strong>.</li>

<li><span class="news-date">[2025/5]</span> Our paper “FIC-TSC: Learning Time Series Classification with Fisher Information Constraint” (<a href="https://arxiv.org/pdf/2505.06114?" target="_blank">link</a>) is accepted by <strong>ICML 2025</strong>.</li>

<li><span class="news-date">[2025/3]</span> Our paper “Driving Towards Inclusion: A Systematic Review of AI-Powered Accessibility Enhancements for People with Disability in Autonomous Vehicles” (<a href="https://ieeexplore.ieee.org/iel8/6287639/6514899/10945350.pdf" target="_blank">link</a>) is accepted for publication in <strong>IEEE Access</strong>.</li>

<li><span class="news-date">[2025/2]</span> Our paper “Gaussian Differential Assessment of Sequential STEM Radiation Damage in Beam-Sensitive Materials” (<a href="https://academic.oup.com/mam/article-pdf/31/Supplement_1/ozaf048.1065/63848042/ozaf048.1065.pdf" target="_blank">link</a>) is accepted for publication in <strong>Microscopy and Microanalysis</strong>.</li>

<li><span class="news-date">[2025/1]</span> Our paper “Cracking Instance Jigsaw Puzzles: An Alternative to Multiple Instance Learning for Whole Slide Image Analysis” (<a href="https://openaccess.thecvf.com/content/ICCV2025/papers/Chen_Cracking_Instance_Jigsaw_Puzzles_An_Alternative_to_Multiple_Instance_Learning_ICCV_2025_paper.pdf" target="_blank">link</a>) was published in <strong>ICCV 2025</strong>.</li>

<li><span class="news-date">[2025/1]</span> Our paper “AtomDiffuser: Time-Aware Degradation Modeling for Drift and Beam Damage in STEM Imaging” (<a href="https://openaccess.thecvf.com/content/ICCV2025W/CV4MS/papers/Wang_AtomDiffuser_Time-Aware_Degradation_Modeling_for_Drift_and_Beam_Damage_in_ICCVW_2025_paper.pdf" target="_blank">link</a>) is accepted in <strong>ICCV 2025 Workshop</strong>.</li>

<li><span class="news-date">[2025/1]</span> Our paper “Adaptive Data Transport Mechanism for UAV Surveillance Missions in Lossy Environments” (<a href="https://ieeexplore.ieee.org/document/10975947" target="_blank">link</a>) was accepted by <strong>IEEE CCNC 2025</strong>.</li>

<li><span class="news-date">[2025/1]</span> Our paper “Diffusion Prism: Enhancing Diversity and Morphology Consistency in Mask-to-Image Diffusion” (<a href="https://openaccess.thecvf.com/content/WACV2025W/ImageQuality/papers/Wang_Diffusion_Prism_Enhancing_Diversity_and_Morphology_Consistency_in_Mask-to-Image_Diffusion_WACVW_2025_paper.pdf" target="_blank">link</a>) was accepted at a <strong>WACV 2025 Workshop</strong>.</li>

<li><span class="news-date">[2024/12]</span> Our paper “Sequence Complementor: Complementing Transformers for Time Series Forecasting with Learnable Sequences” (<a href="https://ojs.aaai.org/index.php/AAAI/article/view/33747" target="_blank">link</a>) is accepted by <strong>AAAI 2025</strong>.</li>

<li><span class="news-date">[2024/12]</span> Our paper “Multimodal Variational Autoencoder: A Barycentric View” (<a href="https://ojs.aaai.org/index.php/AAAI/article/view/34209" target="_blank">link</a>) is accepted by <strong>AAAI 2025</strong>.</li>

<li><span class="news-date">[2024/10]</span> Our paper “Flame Diffuser: Wildfire Image Synthesis Using Mask-Guided Diffusion” (<a href="https://ieeexplore.ieee.org/iel8/10824975/10824942/10826040.pdf" target="_blank">link</a>) was accepted by <strong>IEEE BigData 2024</strong>.</li>

<li><span class="news-date">[2024/10]</span> Our paper “Geographical Information Alignment Boosts Traffic Analysis via Transpose Cross-Attention” (<a href="https://ieeexplore.ieee.org/iel8/10824975/10824942/10825756.pdf" target="_blank">link</a>) was accepted by <strong>IEEE BigData 2024</strong>.</li>

<li><span class="news-date">[2024/10]</span> Outstanding Contribution Award was received from the <strong>UWF4DR Organizing Committee</strong>.</li>

<li><span class="news-date">[2024/10]</span> Our team won <strong>3rd Place</strong>, UWF4DR Task 1: Image Quality Assessment.</li>

<li><span class="news-date">[2024/10]</span> Our team won <strong>3rd Place</strong>, UWF4DR Task 3: Diabetic Macular Edema Identification.</li>

<li><span class="news-date">[2024/8]</span> Our paper “Enhancing Graph Neural Networks for Large-Scale Traffic Incident Analysis with Concurrency Hypothesis” (<a href="https://par.nsf.gov/servlets/purl/10654028" target="_blank">link</a>) is accepted by <strong>ACM SIGSPATIAL 2024 (Oral)</strong>.</li>

<li><span class="news-date">[2024/8]</span> Our paper “Learning on Bandwidth-Constrained Multi-Source Data with MIMO-Inspired DPP MAP Inference” (<a href="https://ieeexplore.ieee.org/document/10580972/" target="_blank">link</a>) is accepted by <strong>IEEE Transactions on Machine Learning in Communications and Networking</strong>.</li>

<li><span class="news-date">[2024/8]</span> <strong>Funded project:</strong> “Anomaly Detection for Resilient Autonomy-Enabled Vehicle Systems” is awarded by <strong>US Army / VIPR-GS</strong>.</li>

<li><span class="news-date">[2024/8]</span> Our paper “RD-DPP: Rate-Distortion Theory Meets Determinantal Point Processes for Diverse Data Selection” (<a href="https://ieeexplore.ieee.org/iel8/10943266/10943193/10943408.pdf" target="_blank">link</a>) was accepted by <strong>WACV 2025</strong>.</li>

<li><span class="news-date">[2024/7]</span> Our paper “DGR-MIL: Exploring Diverse Global Representation in Multiple Instance Learning for Whole Slide Image Classification” (<a href="https://arxiv.org/abs/2407.03575" target="_blank">link</a>) is accepted by <strong>ECCV 2024</strong>.</li>

<li><span class="news-date">[2024/7]</span> Our paper “Quantification of Cardiac Capillarization in Basement-Membrane-Immunostained Myocardial Slices Using Segment Anything Model” (<a href="https://www.nature.com/articles/s41598-024-65567-3" target="_blank">link</a>) is published in <strong>Scientific Reports</strong>.</li>

<li><span class="news-date">[2024/7]</span> Our paper “A Comprehensive Survey of Research towards AI-Enabled Unmanned Aerial Systems in Pre-, Active-, and Post-Wildfire Management” (<a href="https://www.sciencedirect.com/science/article/pii/S1566253524001477" target="_blank">link</a>) was published in <strong>Information Fusion</strong>.</li>

<li><span class="news-date">[2024/6]</span> Our paper “Quantification of Cardiac Capillarization in Single-Immunostained Myocardial Slices Using Weakly Supervised Instance Segmentation” (<a href="https://arxiv.org/abs/2311.18173" target="_blank">link</a>) was published in <strong>Scientific Reports</strong>.</li>

<li><span class="news-date">[2024/6]</span> Our paper “SelfReg-UNet: Self-Regularized UNet for Medical Image Segmentation” (<a href="https://arxiv.org/pdf/2406.14896?" target="_blank">link</a>) is accepted by <strong>MICCAI 2024</strong>.</li>

<li><span class="news-date">[2024/6]</span> Our paper “Quantification of Cardiac Capillarization in Myocardial Slices Using Segment Anything Model” (<a href="https://www.nature.com/articles/s41598-024-65567-3.pdf" target="_blank">link</a>) is accepted by <strong>Nature Scientific Reports</strong>.</li>

<li><span class="news-date">[2024/5]</span> Our paper “TimeMIL: Advancing Multivariate Time Series Classification via a Time-Aware Multiple Instance Learning Framework” (<a href="https://arxiv.org/abs/2405.03140" target="_blank">link</a>) is accepted by <strong>ICML 2024</strong>.</li>

<li><span class="news-date">[2025/3]</span> Our paper “Graph-Based Deep Reinforcement Learning Aided by Transformers for Multi-Agent Cooperation” (<a href="https://arxiv.org/pdf/2504.08195" target="_blank">link</a>) was accepted by <strong>IEEE ICC 2025 Workshops</strong>.</li>

<li><span class="news-date">[2024/4]</span> Our paper “Imaging Signal Recovery Using Neural Network Priors Under Uncertain Forward Model Parameters” (<a href="https://arxiv.org/abs/2405.02944" target="_blank">link</a>) is accepted by <strong>CVPR 2024 Workshops (Oral)</strong>.</li>

<li><span class="news-date">[2024/4]</span> Our paper “nnMobileNet: Rethinking CNN Architectures for Retinopathy Research” (<a href="https://books.google.com/books?hl=en&lr=&id=H5BdEQAAQBAJ&oi=fnd&pg=PA155&dq=info:E-zVu8EaTFsJ:scholar.google.com&ots=ArmgF467t7&sig=rUGwLzjeNNCQgT5GN53GmyZavXQ#v=onepage&q&f=false" target="_blank">link</a>) is accepted by <strong>CVPR 2024 Workshops</strong>.</li>

<li><span class="news-date">[2024/4]</span> <strong>Funded project:</strong> “Learning-Based Semantic Communication for Unmanned Aerial Systems” is awarded by <strong>DoD / MIT Lincoln Laboratory</strong>.</li>

<li><span class="news-date">[2024/3]</span> Our paper “IC-GAN: An Improved Conditional Generative Adversarial Network for RGB-to-IR Image Translation with Applications to Forest Fire Monitoring” (<a href="https://www.sciencedirect.com/science/article/am/pii/S0957417423024648" target="_blank">link</a>) was published in <strong>Expert Systems with Applications</strong>.</li>
  

  
</p>

  
  
</body>
</html>

<!-- 

This is the front page of a website that is powered by the [academicpages template](https://github.com/academicpages/academicpages.github.io) and hosted on GitHub pages. [GitHub pages](https://pages.github.com) is a free service in which websites are built and hosted from code and data stored in a GitHub repository, automatically updating when a new commit is made to the respository. This template was forked from the [Minimal Mistakes Jekyll Theme](https://mmistakes.github.io/minimal-mistakes/) created by Michael Rose, and then extended to support the kinds of content that academics have: publications, talks, teaching, a portfolio, blog posts, and a dynamically-generated CV. You can fork [this repository](https://github.com/academicpages/academicpages.github.io) right now, modify the configuration and markdown files, add your own PDFs and other content, and have your own site for free, with no ads! An older version of this template powers my own personal website at [stuartgeiger.com](http://stuartgeiger.com), which uses [this Github repository](https://github.com/staeiou/staeiou.github.io).

A data-driven personal website
======
Like many other Jekyll-based GitHub Pages templates, academicpages makes you separate the website's content from its form. The content & metadata of your website are in structured markdown files, while various other files constitute the theme, specifying how to transform that content & metadata into HTML pages. You keep these various markdown (.md), YAML (.yml), HTML, and CSS files in a public GitHub repository. Each time you commit and push an update to the repository, the [GitHub pages](https://pages.github.com/) service creates static HTML pages based on these files, which are hosted on GitHub's servers free of charge.

Many of the features of dynamic content management systems (like Wordpress) can be achieved in this fashion, using a fraction of the computational resources and with far less vulnerability to hacking and DDoSing. You can also modify the theme to your heart's content without touching the content of your site. If you get to a point where you've broken something in Jekyll/HTML/CSS beyond repair, your markdown files describing your talks, publications, etc. are safe. You can rollback the changes or even delete the repository and start over -- just be sure to save the markdown files! Finally, you can also write scripts that process the structured data on the site, such as [this one](https://github.com/academicpages/academicpages.github.io/blob/master/talkmap.ipynb) that analyzes metadata in pages about talks to display [a map of every location you've given a talk](https://academicpages.github.io/talkmap.html).

Getting started
======
1. Register a GitHub account if you don't have one and confirm your e-mail (required!)
1. Fork [this repository](https://github.com/academicpages/academicpages.github.io) by clicking the "fork" button in the top right. 
1. Go to the repository's settings (rightmost item in the tabs that start with "Code", should be below "Unwatch"). Rename the repository "[your GitHub username].github.io", which will also be your website's URL.
1. Set site-wide configuration and create content & metadata (see below -- also see [this set of diffs](http://archive.is/3TPas) showing what files were changed to set up [an example site](https://getorg-testacct.github.io) for a user with the username "getorg-testacct")
1. Upload any files (like PDFs, .zip files, etc.) to the files/ directory. They will appear at https://[your GitHub username].github.io/files/example.pdf.  
1. Check status by going to the repository settings, in the "GitHub pages" section

Site-wide configuration
------
The main configuration file for the site is in the base directory in [_config.yml](https://github.com/academicpages/academicpages.github.io/blob/master/_config.yml), which defines the content in the sidebars and other site-wide features. You will need to replace the default variables with ones about yourself and your site's github repository. The configuration file for the top menu is in [_data/navigation.yml](https://github.com/academicpages/academicpages.github.io/blob/master/_data/navigation.yml). For example, if you don't have a portfolio or blog posts, you can remove those items from that navigation.yml file to remove them from the header. 

Create content & metadata
------
For site content, there is one markdown file for each type of content, which are stored in directories like _publications, _talks, _posts, _teaching, or _pages. For example, each talk is a markdown file in the [_talks directory](https://github.com/academicpages/academicpages.github.io/tree/master/_talks). At the top of each markdown file is structured data in YAML about the talk, which the theme will parse to do lots of cool stuff. The same structured data about a talk is used to generate the list of talks on the [Talks page](https://academicpages.github.io/talks), each [individual page](https://academicpages.github.io/talks/2012-03-01-talk-1) for specific talks, the talks section for the [CV page](https://academicpages.github.io/cv), and the [map of places you've given a talk](https://academicpages.github.io/talkmap.html) (if you run this [python file](https://github.com/academicpages/academicpages.github.io/blob/master/talkmap.py) or [Jupyter notebook](https://github.com/academicpages/academicpages.github.io/blob/master/talkmap.ipynb), which creates the HTML for the map based on the contents of the _talks directory).

**Markdown generator**

I have also created [a set of Jupyter notebooks](https://github.com/academicpages/academicpages.github.io/tree/master/markdown_generator
) that converts a CSV containing structured data about talks or presentations into individual markdown files that will be properly formatted for the academicpages template. The sample CSVs in that directory are the ones I used to create my own personal website at stuartgeiger.com. My usual workflow is that I keep a spreadsheet of my publications and talks, then run the code in these notebooks to generate the markdown files, then commit and push them to the GitHub repository.

How to edit your site's GitHub repository
------
Many people use a git client to create files on their local computer and then push them to GitHub's servers. If you are not familiar with git, you can directly edit these configuration and markdown files directly in the github.com interface. Navigate to a file (like [this one](https://github.com/academicpages/academicpages.github.io/blob/master/_talks/2012-03-01-talk-1.md) and click the pencil icon in the top right of the content preview (to the right of the "Raw | Blame | History" buttons). You can delete a file by clicking the trashcan icon to the right of the pencil icon. You can also create new files or upload files by navigating to a directory and clicking the "Create new file" or "Upload files" buttons. 

Example: editing a markdown file for a talk
![Editing a markdown file for a talk](/images/editing-talk.png)

For more info
------
More info about configuring academicpages can be found in [the guide](https://academicpages.github.io/markdown/). The [guides for the Minimal Mistakes theme](https://mmistakes.github.io/minimal-mistakes/docs/configuration/) (which this theme was forked from) might also be helpful. 

-->
